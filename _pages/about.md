---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently an Associate Professor in the [Faculty of Information Science and Engineering,](https://it.ouc.edu.cn/) [Ocean University of China](www.ouc.edu.cn). Before I joined OUC, I worked as an Assistant Professor in [Centre for Artificial Intelligence and Robotics (CAIR), Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences](https://www.cair-cas.org.hk/) from 2022 to 2025. I received my Ph.D. degree from [Institute of Automation, Chinese Academy of Sciences](http://www.ia.cas.cn/) (Beijing, China), under the supervision of [Prof. Zhaoxiang Zhang](https://www.zhaoxiangzhang.net) in 2022. I received my B.E. degree from [Northeastern University](https://www.neu.edu.cn/) (Shenyang, China) in 2016.

My research interests focus on 3D generative AI and Embodied AI, including 3D scene generation, 3D reconstruction, MLLMs, image/video generation and robotics. 
Please do not hesitate to reach out if you would like to explore possible collaboration.



# üî• News
- *2025.06*: &nbsp;üéâüéâ One paper has been accepted by [MICCAI 2025](https://conferences.miccai.org/2025/en/). 
- *2025.04*: &nbsp;üéâüéâ One paper has been accepted by IEEE TPAMI.
- *2025.04*: &nbsp;üéâüéâ One paper has been accepted by IJCV.


# üìù Selected Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2025</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun


<div class='paper-box'><div class='paper-box-image'><div class="badge">T-PAMI 2024</div><img src='images/ATP.png' alt="sym"></div>
<div class='paper-box-text' markdown="1">

**A Curriculum-style Self-training Approach for Source-free Semantic Segmentation** [[Paper](https://arxiv.org/pdf/2106.11653)] [[code](https://github.com/yxiwang/ATP)] \\
**Yuxi Wang**, Jian Liang, Zhaoxiang Zhang. **IEEE TPAMI 2024**

</div>
</div>

<style>
.paper-box {
  display: flex;          
  align-items: flex-start;    
  margin-bottom: 25px;
}

.paper-box-image {
  position: relative;
  margin-right: 20px;     
}

.paper-box-image img {
  width: 140px;           
  height: auto;           
  border-radius: 4px;    
}
</style>

<div class="paper-box">
  <!-- ÂõæÁâáÈÉ®ÂàÜ -->
  <div class="paper-box-image">
    <span class="badge">ICLR 2025</span>
    <img src="images/ATP.png" alt="Paper Image">
  </div>

  <!-- ÊñáÂ≠óÈÉ®ÂàÜ -->
  <div class="paper-box-text">
    <strong>CityGaussianV2: Efficient and Geometrically Accurate Reconstruction for Large-Scale Scenes</strong>
    [<a href="https://example.com/paper">Paper</a>] 
    [<a href="https://example.com/project">Project</a>]
    <br><br>
    Yang Liu, <strong>Chuanchen Luo</strong>, Zhongkai Mao, Junran Peng, Zhaoxiang Zhang
  </div>
</div>

<style>
.paper-box {
  display: flex;             
  align-items: flex-start;    
  margin-bottom: 25px;       
}

.paper-box-image {
  position: relative;         
  margin-right: 20px;         
}

.paper-box-image img {
  width: 260px;              
  height: auto;              
  border-radius: 4px;        
  box-shadow: 0 2px 6px rgba(0,0,0,0.15);
}

.badge {
  position: absolute;
  top: 10px;
  left: 10px;
  background: #1E40AF;        
  color: #fff;
  font-size: 13px;
  font-weight: bold;
  padding: 2px 8px;
  border-radius: 3px;
}

.paper-box-text {
  max-width: 700px;
  font-size: 15px;
  line-height: 1.6;
}

.paper-box-text strong {
  font-weight: 600;
}

.paper-box-text a {
  color: #1E3A8A;
  text-decoration: none;
}

.paper-box-text a:hover {
  text-decoration: underline;
}
</style>


- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
